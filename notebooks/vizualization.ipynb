{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from common.utils import Params, set_logger, copy_weight, load_checkpoint, save_checkpoint_pos_ori, write_log, get_lr, write_train_summary_scalars, write_val_summary_joint, change_momentum\n",
    "from features.networks import TGraphNet, TGraphNetSeq\n",
    "from vizualization.vizualize import plot_adjacency_matrix, plot_pose_animation, plot_poses_only, plot_poses_merged\n",
    "from common.h36m_skeleton import get_node_names, get_edge_names\n",
    "import torch\n",
    "from graph import Graph\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from pytransform3d import rotations as pr\n",
    "from pytransform3d.plot_utils import make_3d_axis\n",
    "import mpl_toolkits.mplot3d.art3d as art3d\n",
    "from matplotlib.transforms import Affine2D\n",
    "from matplotlib.text import TextPath\n",
    "from matplotlib.patches import PathPatch\n",
    "from common.h36m_skeleton import *\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from data.h36m_dataset import Human36M\n",
    "from data.pw3d_dataset import PW3D\n",
    "from data.dhp_dataset import DHPDataset\n",
    "from common.h36m_skeleton import joint_id_to_names\n",
    "from data.generators import ChunkedGenerator_Seq, UnchunkedGenerator_Seq, ChunkedGenerator_Frame, ChunkedGenerator_Seq2Seq, eval_data_prepare, ChunkedGeneratorDHP\n",
    "from pytransform3d.plot_utils import make_3d_axis\n",
    "\n",
    "from evaluation import mpjpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters\n",
    "json_path = os.path.join('../models/stgcn/root_rel/params.json')\n",
    "assert os.path.isfile(json_path), \"No json file found at {}\".format(json_path)\n",
    "params = Params(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TGraphNetSeq(infeat_v=params.input_node_feat,\n",
    "                  infeat_e=params.input_edge_feat,\n",
    "                  nhid_v=params.num_hidden_nodes,\n",
    "                  nhid_e=params.num_hidden_edges,\n",
    "                  n_oute=params.output_edge_feat,\n",
    "                  n_outv=params.output_node_feat,\n",
    "                  gcn_window=params.gcn_window,\n",
    "                  tcn_window=params.tcn_window,\n",
    "                  in_frames=params.in_frames,\n",
    "                  gconv_stages=params.gconv_stages,\n",
    "                  num_groups=params.num_groups,\n",
    "                  dropout=params.dropout,\n",
    "                  aggregate=params.aggregate,\n",
    "                  use_residual_connections=params.use_residual_connections,\n",
    "                  use_non_parametric=params.use_non_parametric,\n",
    "                  use_edge_conv=params.use_edge_conv,\n",
    "                  learn_adj=False)\n",
    "\n",
    "load_checkpoint('../models/stgcn/root_rel/best_pos.pth.tar', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = os.path.join('../models/stgcn/run1/params.json')\n",
    "assert os.path.isfile(json_path), \"No json file found at {}\".format(json_path)\n",
    "params = Params(json_path)\n",
    "\n",
    "model_single = TGraphNet(infeat_v=params.input_node_feat,\n",
    "                  infeat_e=params.input_edge_feat,\n",
    "                  nhid_v=params.num_hidden_nodes,\n",
    "                  nhid_e=params.num_hidden_edges,\n",
    "                  n_oute=params.output_edge_feat,\n",
    "                  n_outv=params.output_node_feat,\n",
    "                  gcn_window=params.gcn_window,\n",
    "                  tcn_window=params.tcn_window,\n",
    "                  in_frames=params.in_frames,\n",
    "                  gconv_stages=params.gconv_stages,\n",
    "                  num_groups=params.num_groups,\n",
    "                  dropout=params.dropout,\n",
    "                  aggregate=params.aggregate,\n",
    "                  use_residual_connections=params.use_residual_connections,\n",
    "                  use_non_parametric=params.use_non_parametric,\n",
    "                  use_edge_conv=params.use_edge_conv,\n",
    "                  learn_adj=False)\n",
    "\n",
    "load_checkpoint('../models/stgcn/run1/best_pos.pth.tar', model_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_adjacency_matrix(model_single.state_dict()['adj_v'][3].cpu(), node_names=get_node_names(3), annotate_values=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Predicted 3D Poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = Human36M(data_dir=\"/media/HDD3/datasets/Human3.6M/pose_zip\", train=False, ds_category=params.ds_category, actions='SittingDown')\n",
    "# test_dataset = PW3D(data_file=\"../data/pw3d_test.pkl\", actions=['downtown_runForBus_01_0'])\n",
    "test_dataset = DHPDataset(data_dir=\"../data/\", train=False)\n",
    "\n",
    "val_generator = ChunkedGeneratorDHP(1, cameras=None, poses_2d=test_dataset.pos2d, poses_3d=test_dataset.pos3d,\n",
    "                          valid_frame=test_dataset.valid_frame, train=False,\n",
    "                                                chunk_length=1, pad=40, out_all=True, shuffle=False,\n",
    "                                                augment=False, reverse_aug=False,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.pos2d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam, pos2d, pos3d, angles_6d, edge_features = test_dataset.cam, test_dataset.pos2d, test_dataset.pos3d_centered, [], []\n",
    "val_generator = ChunkedGenerator_Seq2Seq(1, cameras=cam, poses_2d=pos2d, poses_3d=pos3d,\n",
    "                                                   chunk_length=31, pad=25, out_all=True, shuffle=False,\n",
    "                                                   augment=False, reverse_aug=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam, pos2d, pos3d, angles_6d, edge_features = test_dataset.cam, test_dataset.pos2d, test_dataset.pos3d_centered, [], []\n",
    "val_generator_single = ChunkedGenerator_Seq2Seq(1, cameras=cam, poses_2d=pos2d, poses_3d=pos3d,\n",
    "                                                   chunk_length=1, pad=40, out_all=True, shuffle=False,\n",
    "                                                   augment=False, reverse_aug=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device).eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import PillowWriter, FFMpegWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get MPJPE per each frame\n",
    "\n",
    "def mpjpe(predicted, target):\n",
    "    \"\"\"\n",
    "    Mean per-joint position error (i.e. mean Euclidean distance),\n",
    "    often referred to as \"Protocol #1\" in many papers.\n",
    "    returns mean error across all data points\n",
    "    and mean per joint error 17 x 1\n",
    "    \"\"\"\n",
    "    assert predicted.shape == target.shape\n",
    "    return torch.mean(torch.norm(predicted - target, dim=len(target.shape)-1), dim=(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_pos3d = np.empty([0, 17, 3])\n",
    "pred_pose3d = np.empty([0, 17, 3])\n",
    "mpjpe_err = np.empty([0])\n",
    "mpjpe_err_traj = np.empty([0])\n",
    "\n",
    "i_batch = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for seq_name, start_3d, end_3d, flip, reverse in val_generator.pairs:\n",
    "      cam, batch_3d, batch_2d, seq, subject, cam_ind = val_generator.get_batch(seq_name, start_3d, end_3d, flip, reverse)\n",
    "\n",
    "      input_2d = torch.FloatTensor(batch_2d).to(device).reshape(-1, 81, 17, 2)\n",
    "      target_pose_3d = torch.FloatTensor(batch_3d).to(device).reshape(-1, 81, 17, 3)\n",
    "      # cameras_val = torch.from_numpy(cameras_val.astype('float32')).to(device)\n",
    "\n",
    "      middle_index = int((target_pose_3d.shape[1] - 1) / 2)\n",
    "      pad = 0\n",
    "      start_index = middle_index - pad\n",
    "      end_index = middle_index + pad + 1\n",
    "      B, T, J, D = target_pose_3d.shape\n",
    "\n",
    "      predicted_pos3d = model(input_2d)\n",
    "      predicted_pos3d_center = predicted_pos3d[:, start_index:end_index].reshape(B, (2 * pad + 1), J, D)\n",
    "\n",
    "      # target_angle_6d = target_angle_6d[:, middle_index].view_as(predicted_angle_6d)\n",
    "      target_pose_3d = target_pose_3d.view_as(predicted_pos3d)\n",
    "      target_pose_3d_center = target_pose_3d[:, start_index:end_index].reshape(B, (2 * pad + 1), J, D)\n",
    "\n",
    "        #   target_pose_3d_center[:, :, :1] = 0\n",
    "        #   predicted_pos3d_center[:, :, :1] = 0\n",
    "      target_pose_3d_center[:, :, 1:] += target_pose_3d_center[:, :, :1]\n",
    "      predicted_pos3d_center[:, :, 1:] += predicted_pos3d_center[:, :, :1]\n",
    "\n",
    "        # mpjpe\n",
    "      _mpjpe = mpjpe(target_pose_3d_center.cpu().data, predicted_pos3d_center.cpu().data)[0].numpy().reshape(-1)\n",
    "      _mpjpe_traj = mpjpe(target_pose_3d_center.cpu().data[:, :, :1], predicted_pos3d_center.cpu().data[:, :, :1])[0].numpy().reshape(-1)\n",
    "\n",
    "      if i_batch == 0:\n",
    "          gt_pos3d = target_pose_3d_center.reshape(-1, J, D).cpu().data.numpy()\n",
    "          pred_pose3d = predicted_pos3d_center.reshape(-1, J, D).cpu().data.numpy()\n",
    "          mpjpe_err = np.array(_mpjpe).reshape(-1)\n",
    "          mpjpe_err_traj = np.array(_mpjpe_traj).reshape(-1)\n",
    "      else:\n",
    "          gt_pos3d = np.concatenate((gt_pos3d, target_pose_3d_center.reshape(-1, J, D).cpu().data.numpy()), axis=0)\n",
    "          pred_pose3d = np.concatenate((pred_pose3d, predicted_pos3d_center.reshape(-1, J, D).cpu().data.numpy()), axis=0)\n",
    "          mpjpe_err = np.concatenate((mpjpe_err, np.array(_mpjpe).reshape(-1)), axis=0)\n",
    "          mpjpe_err_traj = np.concatenate((mpjpe_err_traj, np.array(_mpjpe_traj).reshape(-1)), axis=0)\n",
    "\n",
    "      i_batch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# actions = ['Directions', 'Discussion','Eating', 'Greeting','Phoning','Photo', 'Posing', 'Purchases','Sitting', 'SittingDown', 'Smoking', 'Waiting','WalkDog','WalkTogether','Walking']\n",
    "# actions = ['Eating']\n",
    "actions = ['WalkDog']\n",
    "\n",
    "gt_pos3d = np.empty([0, 17, 3])\n",
    "pred_pose3d = np.empty([0, 17, 3])\n",
    "mpjpe_err = np.empty([0])\n",
    "mpjpe_err_traj = np.empty([0])\n",
    "\n",
    "i_batch = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cameras_val, batch_3d, batch_6d, batch_2d, batch_edge in val_generator.next_epoch():\n",
    "        input_2d = torch.FloatTensor(batch_2d).to(device)\n",
    "        target_pose_3d = torch.FloatTensor(batch_3d).to(device)\n",
    "        cameras_val = torch.from_numpy(cameras_val.astype('float32')).to(device)\n",
    "\n",
    "        middle_index = int((target_pose_3d.shape[1] - 1) / 2)\n",
    "        pad = 15\n",
    "        start_index = middle_index - pad\n",
    "        end_index = middle_index + pad + 1\n",
    "        B, T, J, D = target_pose_3d.shape\n",
    "\n",
    "        predicted_pos3d = model(input_2d)\n",
    "        predicted_pos3d_center = predicted_pos3d[:, start_index:end_index].reshape(B, (2 * pad + 1), J, D)\n",
    "\n",
    "        # target_angle_6d = target_angle_6d[:, middle_index].view_as(predicted_angle_6d)\n",
    "        target_pose_3d = target_pose_3d.view_as(predicted_pos3d)\n",
    "        target_pose_3d_center = target_pose_3d[:, start_index:end_index].reshape(B, (2 * pad + 1), J, D)\n",
    "\n",
    "        # target_pose_3d_center[:, :, :1] = 0\n",
    "        # predicted_pos3d_center[:, :, :1] = 0\n",
    "        target_pose_3d_center[:, :, 1:] += target_pose_3d_center[:, :, :1]\n",
    "        predicted_pos3d_center[:, :, 1:] += predicted_pos3d_center[:, :, :1]\n",
    "\n",
    "        # mpjpe\n",
    "        _mpjpe = mpjpe(target_pose_3d_center.cpu().data, predicted_pos3d_center.cpu().data)[0].numpy().reshape(-1)\n",
    "        _mpjpe_traj = mpjpe(target_pose_3d_center.cpu().data[:, :, :1], predicted_pos3d_center.cpu().data[:, :, :1])[0].numpy().reshape(-1)\n",
    "\n",
    "        if i_batch == 0:\n",
    "            gt_pos3d = target_pose_3d_center.reshape(-1, J, D).cpu().data.numpy()\n",
    "            pred_pose3d = predicted_pos3d_center.reshape(-1, J, D).cpu().data.numpy()\n",
    "            mpjpe_err = np.array(_mpjpe).reshape(-1)\n",
    "            mpjpe_err_traj = np.array(_mpjpe_traj).reshape(-1)\n",
    "        else:\n",
    "            gt_pos3d = np.concatenate((gt_pos3d, target_pose_3d_center.reshape(-1, J, D).cpu().data.numpy()), axis=0)\n",
    "            pred_pose3d = np.concatenate((pred_pose3d, predicted_pos3d_center.reshape(-1, J, D).cpu().data.numpy()), axis=0)\n",
    "            mpjpe_err = np.concatenate((mpjpe_err, np.array(_mpjpe).reshape(-1)), axis=0)\n",
    "            mpjpe_err_traj = np.concatenate((mpjpe_err_traj, np.array(_mpjpe_traj).reshape(-1)), axis=0)\n",
    "\n",
    "        i_batch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single frame prediction\n",
    "\n",
    "import json\n",
    "\n",
    "actions = ['WalkDog']\n",
    "\n",
    "gt_pos3d = np.empty([0, 17, 3])\n",
    "pred_pose3d = np.empty([0, 17, 3])\n",
    "mpjpe_err = np.empty([0])\n",
    "\n",
    "i_batch = 0\n",
    "\n",
    "model_single.to(device).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cameras_val, batch_3d, batch_6d, batch_2d, batch_edge in val_generator_single.next_epoch():\n",
    "        input_2d = torch.FloatTensor(batch_2d).to(device)\n",
    "        target_pose_3d = torch.FloatTensor(batch_3d).to(device)\n",
    "\n",
    "        # out_3d, input_2d = eval_data_prepare(params.in_frames, input_2d, target_pose_3d)\n",
    "        # target_pose_3d = out_3d.to(device)\n",
    "        # # target_angle_6d = out_6d.to(device)\n",
    "        # input_2d = input_2d.to(device)\n",
    "\n",
    "        middle_index = int((target_pose_3d.shape[1] - 1) / 2)\n",
    "\n",
    "        predicted_pos3d_center = model_single(input_2d[:, middle_index])\n",
    "        # predicted_pos3d_center[:, :, 0] = 0  # 0 out hip pos\n",
    "\n",
    "        # target_angle_6d = target_angle_6d[:, middle_index].view_as(predicted_angle_6d)\n",
    "        target_pose_3d_center = target_pose_3d[:, middle_index].view_as(predicted_pos3d_center)\n",
    "        # target_pose_3d_center[:, :, 0] = 0  # 0 out the hip pose\n",
    "\n",
    "        # mpjpe\n",
    "        _mpjpe = mpjpe(target_pose_3d_center.cpu().data, predicted_pos3d_center.cpu().data)[0].numpy().reshape(-1)\n",
    "\n",
    "        if i_batch == 0:\n",
    "            gt_pos3d = target_pose_3d_center.reshape(-1, 17, 3).cpu().data.numpy()\n",
    "            pred_pose3d = predicted_pos3d_center.reshape(-1, 17, 3).cpu().data.numpy()\n",
    "            mpjpe_err = np.array(_mpjpe).reshape(-1)\n",
    "        else:\n",
    "            gt_pos3d = np.concatenate((gt_pos3d, target_pose_3d_center.reshape(-1, 17, 3).cpu().data.numpy()), axis=0)\n",
    "            pred_pose3d = np.concatenate((pred_pose3d, predicted_pos3d_center.reshape(-1, 17, 3).cpu().data.numpy()), axis=0)\n",
    "            mpjpe_err = np.concatenate((mpjpe_err, np.array(_mpjpe).reshape(-1)), axis=0)\n",
    "\n",
    "\n",
    "        i_batch += 1\n",
    "\n",
    "        if i_batch > 1000:\n",
    "          break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 30\n",
    "\n",
    "def plot_pose_animation(pred_pos3d, gt_pos3d, mpjpe_err=None, action=\"\", num_frames=81, save_path=None):\n",
    "    assert save_path is not None\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    ax = make_3d_axis(20, pos=int('11{}'.format(1)), n_ticks=5,)\n",
    "\n",
    "    def animate(i):\n",
    "        ax.clear()\n",
    "        pred_pos = pred_pos3d[i]\n",
    "        gt_pos = gt_pos3d[i]\n",
    "        pos_err = mpjpe_err[i] if mpjpe_err is not None else 0\n",
    "        ax.view_init(-80, 90) # view them from front\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_zticklabels([])\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_zlabel(\"\")\n",
    "        ax.set_ylim(-scale, scale)\n",
    "        ax.set_xlim(-scale, scale)\n",
    "        ax.set_zlim(-scale, scale)\n",
    "\n",
    "        plot_poses_only(gt_pos, pred_pos, \"\", pos_err, ax=ax, x_offset=-20, y_offset=-14)\n",
    "\n",
    "    ani = FuncAnimation(fig, animate, frames=num_frames, repeat=False, interval=10) #interval: Delay between frames in milliseconds\n",
    "\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = plot_pose_animation(pred_pose3d - gt_pos3d[:, :1], gt_pos3d=gt_pos3d - gt_pos3d[:, :1], save_path=\"\", num_frames=500)\n",
    "anim.save(\"../reports/sittingdown.gif\", dpi=50, writer=PillowWriter(fps=24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.argsort(mpjpe_err_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpjpe_err_traj[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpjpe_err.shape, gt_pos3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = [0.25, 0.5, 0.75, 0.95, 0.99, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in percentiles:\n",
    "  perc_index = (mpjpe_err.shape[0] - 1) * p\n",
    "  perc_index = int(perc_index + 0.5)\n",
    "\n",
    "  lab = \"Median\" if p == 0.5 else f\"{int(p * 100)}th Percentile\"\n",
    "  lab = \"Worst\" if p == 1 else lab\n",
    "\n",
    "  sns.set_style(\"whitegrid\")\n",
    "  pose_scale = 18\n",
    "\n",
    "  fig = plt.figure(figsize=(12, 12))\n",
    "  ax = make_3d_axis(20, pos=int('11{}'.format(1)), n_ticks=5,)\n",
    "  ax.clear()\n",
    "  ax.view_init(-90, 90) # view them from front\n",
    "  ax.set_xticklabels([])\n",
    "  ax.set_yticklabels([])\n",
    "  ax.set_zticklabels([])\n",
    "  ax.set_xlabel(\"\")\n",
    "  ax.set_zlabel(\"\")\n",
    "  ax.set_ylim(-pose_scale, pose_scale)\n",
    "  ax.set_xlim(-pose_scale, pose_scale)\n",
    "  ax.set_zlim(-pose_scale, pose_scale)\n",
    "\n",
    "  \n",
    "  ax.yaxis.set_rotate_label(False)\n",
    "  ax.set_ylabel(lab, fontsize=24, rotation=90)\n",
    "\n",
    "  # bbox_inches='tight'\n",
    "  plot_poses_merged(gt_pos3d[order][perc_index] - gt_pos3d[order][perc_index][:1], pred_pose3d[order][perc_index] - gt_pos3d[order][perc_index][:1], action=\"SittingDown\", mpjpe=mpjpe_err[order][perc_index], ax=ax, x_offset=0, y_offset=-2, text_y=16)\n",
    "  plt.tight_layout()\n",
    "\n",
    "  # plt.savefig(f\"../reports/dhp_plots_traj/dhp_subplots{p}th.png\", bbox_inches='tight', pad_inches = 0, dpi=300)\n",
    "  # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in percentiles:\n",
    "  perc_index = (mpjpe_err.shape[0] - 1) * p\n",
    "  perc_index = int(perc_index + 0.5)\n",
    "\n",
    "  lab = \"Median\" if p == 0.5 else f\"{int(p * 100)}th Percentile\"\n",
    "  lab = \"Worst\" if p == 1 else lab\n",
    "\n",
    "  sns.set_style(\"whitegrid\")\n",
    "  pose_scale = 18\n",
    "\n",
    "  fig = plt.figure(figsize=(24, 12))\n",
    "  ax1 = make_3d_axis(20, pos=int('12{}'.format(1)), n_ticks=5,)\n",
    "  # ax1 = fig.gca(projection=\"3d\")\n",
    "  ax1.clear()\n",
    "  ax1.view_init(30, 90) # view them from front\n",
    "  # ax1.set_xticklabels([])\n",
    "  # ax1.set_yticklabels([])\n",
    "  # ax1.set_zticklabels([])\n",
    "  ax1.set_xlabel(\"X\", fontsize=22)\n",
    "  ax1.set_zlabel(\"Z\", fontsize=22)\n",
    "  ax1.set_ylim(-pose_scale, pose_scale)\n",
    "  ax1.set_xlim(-pose_scale, pose_scale)\n",
    "  ax1.set_zlim(-pose_scale, pose_scale)\n",
    "\n",
    "  ax2 = make_3d_axis(20, pos=int('12{}'.format(2)), n_ticks=5,)\n",
    "  ax2.clear()\n",
    "  ax2.view_init(30, 90) # view them from front\n",
    "  # ax2.set_xticklabels([])\n",
    "  # ax2.set_yticklabels([])\n",
    "  # ax2.set_zticklabels([])\n",
    "  ax2.set_xlabel(\"X\")\n",
    "  ax2.set_zlabel(\"Z\", fontsize=22)\n",
    "  ax2.set_ylim(-pose_scale, pose_scale)\n",
    "  ax2.set_xlim(-pose_scale, pose_scale)\n",
    "  ax2.set_zlim(-pose_scale, pose_scale)\n",
    "\n",
    "  \n",
    "  ax1.yaxis.set_rotate_label(False)\n",
    "  ax1.set_ylabel(lab, fontsize=24, rotation=90)\n",
    "\n",
    "  ax2.yaxis.set_rotate_label(False)\n",
    "  ax2.set_ylabel(lab, fontsize=24, rotation=90)\n",
    "\n",
    "  # bbox_inches='tight'\n",
    "  plot_poses_merged(-(gt_pos3d[order][perc_index]), np.zeros_like(gt_pos3d[order][perc_index]), action=\"SittingDown\", mpjpe=mpjpe_err[order][perc_index], ax=ax1, x_offset=0, y_offset=-2, text_y=16)\n",
    "  plot_poses_merged(np.zeros_like(gt_pos3d[order][perc_index]), -(pred_pose3d[order][perc_index]), action=\"SittingDown\", mpjpe=mpjpe_err[order][perc_index], ax=ax2, x_offset=0, y_offset=-2, text_y=16)\n",
    "  plt.tight_layout()\n",
    "\n",
    "  # plt.savefig(f\"../reports/dhp_plots_traj/dhp_subplots{p}th.png\", bbox_inches='tight', pad_inches = 0, dpi=300)\n",
    "  # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in percentiles:\n",
    "  perc_index = (mpjpe_err.shape[0] - 3) * p\n",
    "  perc_index = int(perc_index + 0.5)\n",
    "\n",
    "  lab = \"Median\" if p == 0.5 else f\"{int(p * 100)}th Percentile\"\n",
    "  lab = \"Worst\" if p == 1 else lab\n",
    "\n",
    "  sns.set_style(\"whitegrid\")\n",
    "  pose_scale = 14\n",
    "\n",
    "  fig = plt.figure(figsize=(12, 12))\n",
    "  ax = make_3d_axis(20, pos=int('11{}'.format(1)), n_ticks=5,)\n",
    "  ax.clear()\n",
    "  ax.view_init(-80, 90) # view them from front\n",
    "  ax.set_xticklabels([])\n",
    "  ax.set_yticklabels([])\n",
    "  ax.set_zticklabels([])\n",
    "  ax.set_xlabel(\"\")\n",
    "  ax.set_zlabel(\"\")\n",
    "  ax.set_ylim(-pose_scale, pose_scale)\n",
    "  ax.set_xlim(-pose_scale, pose_scale)\n",
    "  ax.set_zlim(-pose_scale, pose_scale)\n",
    "\n",
    "  \n",
    "  ax.yaxis.set_rotate_label(False)\n",
    "  ax.set_ylabel(lab, fontsize=24, rotation=90)\n",
    "\n",
    "  # bbox_inches='tight'\n",
    "  plot_poses_merged(gt_pos3d[order][perc_index] - gt_pos3d[order][perc_index][:1], pred_pose3d[order][perc_index] - gt_pos3d[order][perc_index][:1], action=\"Photo\", mpjpe=mpjpe_err[order][perc_index], ax=ax, x_offset=0, y_offset=-2, text_y=13)\n",
    "  plt.tight_layout()\n",
    "\n",
    "  plt.savefig(f\"../reports/traj_plots_h36m/Photo{p}th.png\", bbox_inches='tight', pad_inches = 0, dpi=300)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "arr = np.array([49.7538, 48.3057, 47.8841, 47.6104, 47.7223, 47.3221, 47.2411, 47.2078,\n",
    "        47.1978, 47.1767, 47.1144, 47.0833, 47.0485, 46.9908, 46.9347, 46.9129,\n",
    "        46.8645, 46.8407, 46.8305, 46.7807, 46.7581, 46.7608, 46.7286, 46.7075,\n",
    "        46.6989, 46.6775, 46.6921, 46.7029, 46.6718, 46.6809, 46.7028, 46.6962,\n",
    "        46.6921, 46.6889, 46.6647, 46.6807, 46.6998, 46.6770, 46.6880, 46.7206,\n",
    "        46.7394, 46.7421, 46.7347, 46.7025, 46.7159, 46.7400, 46.7235, 46.7272,\n",
    "        46.7431, 46.7554, 46.7867, 46.7975, 46.7783, 46.7961, 46.8182, 46.8030,\n",
    "        46.8229, 46.8512, 46.8844, 46.9349, 46.9697, 46.9793, 47.0194, 47.0600,\n",
    "        47.0803, 47.1180, 47.1604, 47.2124, 47.2804, 47.3459, 47.3640, 47.4203,\n",
    "        47.4780, 47.4975, 47.5314, 47.6380, 48.0289, 47.9970, 48.4052, 48.8925,\n",
    "  50.4541])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "labs = [' ']*81\n",
    "labs[0] = 1\n",
    "labs[-1] = 81\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style('whitegrid')\n",
    "ax = sns.barplot(y=arr, x=np.arange(1, 82), color=\"steelblue\")\n",
    "ax.set_xticklabels(labs, fontsize=20)\n",
    "ax.set_xlabel(\"Frame\", fontsize=20, fontdict={'weight': 'bold'})\n",
    "ax.set_ylabel(\"MPJPE (mm)\", fontsize=20, fontdict={'weight': 'bold'})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../reports/figures/frame_wise_mpjpe.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_traj(pred_pose3d_first, pred_pose3d_second, joint_idx, savepath=None):\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    # set up a figure twice as wide as it is tall\n",
    "    fig = plt.figure(figsize=(24, 12))\n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=5)  # set the spacing between axes.\n",
    "\n",
    "    # Data for a three-dimensional line\n",
    "    zline = pred_pose3d_first[:, joint_idx, 2]\n",
    "    xline = pred_pose3d_first[:, joint_idx, 0]\n",
    "    yline = pred_pose3d_first[:, joint_idx, 1]\n",
    "    # ax1.set_xlim([-400, 400])\n",
    "    # # ax1.set_zlim([-400, 400])\n",
    "    # ax1.set_ylim([600, 1000])\n",
    "    ax1.plot3D(xline, yline, zline, 'black', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d', sharex = ax1, sharey = ax1, sharez= ax1)\n",
    "\n",
    "    # Data for a three-dimensional line\n",
    "    zline = pred_pose3d_second[:, joint_idx, 2]\n",
    "    xline = pred_pose3d_second[:, joint_idx, 0]\n",
    "    yline = pred_pose3d_second[:, joint_idx, 1]\n",
    "    # ax2.set_xlim([-400, 400])\n",
    "    # # ax1.set_zlim([-400, 400])\n",
    "    # ax2.set_ylim([600, 1000])\n",
    "\n",
    "    ax1.plot3D(xline, yline, zline, 'red', linewidth=1.5, alpha=0.6)\n",
    "\n",
    "    font = {\n",
    "        'family': 'arial',\n",
    "        'color':  'black',\n",
    "        'weight': 'normal',\n",
    "        'size': 24,\n",
    "    }\n",
    "\n",
    "    ax1.set_xlabel(\"X\", fontdict=font, labelpad=8.)\n",
    "    ax2.set_xlabel(\"X\", fontdict=font, labelpad=8.)\n",
    "\n",
    "    ax1.set_ylabel(\"Y\", fontdict=font, labelpad=8.)\n",
    "    ax2.set_ylabel(\"Y\", fontdict=font, labelpad=8.)\n",
    "\n",
    "    ax1.set_zlabel(\"Z\", fontdict=font, labelpad=8.)\n",
    "    ax2.set_zlabel(\"Z\", fontdict=font, labelpad=8.)\n",
    "\n",
    "    ax1.set_title(\"Trajectory of Hip Joint\", fontdict=font)\n",
    "    ax2.set_title(\"Single-Frame Output\", fontdict=font)\n",
    "\n",
    "    # ax1.view_init(elev=-80, azim=90) #Works!\n",
    "\n",
    "    ax1.grid(True)\n",
    "    ax1.set_xticklabels([])\n",
    "    ax1.set_yticklabels([])\n",
    "    ax1.set_zticklabels([])\n",
    "\n",
    "    ax2.grid(True)\n",
    "    ax2.set_xticklabels([])\n",
    "    ax2.set_yticklabels([])\n",
    "    ax2.set_zticklabels([])\n",
    "\n",
    "    \n",
    "    if savepath:\n",
    "        plt.savefig(f\"{savepath}\", bbox_inches='tight', pad_inches = 0, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_traj_cmp(pred_pose3d_first, pred_pose3d_second, joint_idx, savepath=None, scale=0.5):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    # set up a figure twice as wide as it is tall\n",
    "    fig = plt.figure(figsize=(24, 12))\n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=5)  # set the spacing between axes.\n",
    "\n",
    "    # Data for a three-dimensional line\n",
    "    zline = pred_pose3d_first[:, joint_idx, 2]\n",
    "    xline = pred_pose3d_first[:, joint_idx, 0]\n",
    "    yline = pred_pose3d_first[:, joint_idx, 1]\n",
    "    ax1.set_xlim([-scale, scale])\n",
    "    ax1.set_zlim([-scale, scale])\n",
    "    ax1.set_ylim([-scale, scale])\n",
    "    ax1.plot3D(xline, yline, zline, 'royalblue', linewidth=2, alpha=1)\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d', sharex = ax1, sharey = ax1, sharez= ax1)\n",
    "\n",
    "    # Data for a three-dimensional line\n",
    "    zline = pred_pose3d_second[:, joint_idx, 2]\n",
    "    xline = pred_pose3d_second[:, joint_idx, 0]\n",
    "    yline = pred_pose3d_second[:, joint_idx, 1]\n",
    "    ax2.set_xlim([-scale, scale])\n",
    "    ax2.set_zlim([-scale, scale])\n",
    "    ax2.set_ylim([-scale, scale])\n",
    "\n",
    "    ax2.plot3D(xline, yline, zline, 'darkorange', linewidth=2, alpha=1)\n",
    "\n",
    "    font = {\n",
    "        'family': 'arial',\n",
    "        'color':  'black',\n",
    "        'weight': 'normal',\n",
    "        'size': 24,\n",
    "    }\n",
    "\n",
    "    ax1.set_xlabel(\"X\", fontdict=font, labelpad=8.)\n",
    "    ax2.set_xlabel(\"X\", fontdict=font, labelpad=8.)\n",
    "\n",
    "    ax1.set_ylabel(\"Y\", fontdict=font, labelpad=8.)\n",
    "    ax2.set_ylabel(\"Y\", fontdict=font, labelpad=8.)\n",
    "\n",
    "    ax1.set_zlabel(\"Z\", fontdict=font, labelpad=8.)\n",
    "    ax2.set_zlabel(\"Z\", fontdict=font, labelpad=8.)\n",
    "\n",
    "    ax1.set_title(\"Single-Frame Output\", fontdict=font)\n",
    "    ax2.set_title(\"Multi-Frame Output\", fontdict=font)\n",
    "\n",
    "    # ax1.view_init(elev=-80, azim=90) #Works!\n",
    "\n",
    "    ax1.grid(True)\n",
    "    ax1.set_xticklabels([])\n",
    "    ax1.set_yticklabels([])\n",
    "    ax1.set_zticklabels([])\n",
    "\n",
    "    ax2.grid(True)\n",
    "    ax2.set_xticklabels([])\n",
    "    ax2.set_yticklabels([])\n",
    "    ax2.set_zticklabels([])\n",
    "\n",
    "    \n",
    "    if savepath:\n",
    "        plt.savefig(f\"{savepath}\", bbox_inches='tight', pad_inches = 0, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_traj_cmp(pred_pose3d_first=(pred_pose3d - pred_pose3d[:, :1])[100:250] / 1000, pred_pose3d_second=(gt_pos3d - gt_pos3d[:, :1])[100:250] / 1000, joint_idx=12, savepath=\"../reports/traj_plots_h36m/walking_traj_single_lelbow.png\", scale=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {rwrist: 0.4, lwrist: 0.4, relbow: 0.3, lelbow: 0.3}\n",
    "\n",
    "plot_3d_traj_cmp(pred_pose3d_second=(pred_pose3d - pred_pose3d[:, :1])[100:250] / 1000, pred_pose3d_first=(gt_pos3d - gt_pos3d[:, :1])[100:250] / 1000, joint_idx=9, savepath=\"../reports/traj_plots_h36m/walking_traj_multi_head.png\", scale=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((gt_pos3d - gt_pos3d[:, :1]) / 1000)[:, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
